{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OIL_companies.Sentimental.Analysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNo3KtG10NA1nUm6NOIgvIg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gaukhar-ai/DecisionTree/blob/master/OIL_companies_Sentimental_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kwT6NV5k8O2",
        "outputId": "d22dc489-e8ba-4e47-bf54-76bc5e97bd6a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "import matplotlib.pyplot as plt\n",
        "from urllib.request import urlopen, Request\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "from collections import Counter\n",
        "import nltk\n",
        "import spacy\n",
        "import re"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
            "  warnings.warn(\"The twython library has not been installed. \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkgHUa1LlGDT"
      },
      "source": [
        "# Get Data\n",
        "finviz_url = 'https://finviz.com/quote.ashx?t='\n",
        "news_tables = {}"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lg7rVYVJlGAa"
      },
      "source": [
        "# Parameters \n",
        "n = 5 #the # of article headlines displayed per ticker\n",
        "tickers = ['SNP', 'PTR', 'BP', 'XOM', 'TOT', 'CVX', 'MPC']\n",
        "\n",
        "#particularly selected OIL mining companies, since the market is very unique these times,\n",
        "#lots of opportunities in the oil market"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHUczmuYlGGL",
        "outputId": "4c590c57-66b9-4ecf-c819-e0b9d2cd1fca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#cleaning the data by using BeautifulSoup\n",
        "\n",
        "for ticker in tickers:\n",
        "    url = finviz_url + ticker\n",
        "    req = Request(url=url,headers={'user-agent': 'my-app/0.0.1'}) \n",
        "    resp = urlopen(req)    \n",
        "    html = BeautifulSoup(resp, features=\"lxml\")\n",
        "    news_table = html.find(id='news-table')\n",
        "    news_tables[ticker] = news_table\n",
        "\n",
        "try:\n",
        "    for ticker in tickers:\n",
        "        df = news_tables[ticker]\n",
        "        df_tr = df.findAll('tr')\n",
        "    \n",
        "        print ('\\n')\n",
        "        print ('Recent News Headlines for {}: '.format(ticker))\n",
        "        \n",
        "        for i, table_row in enumerate(df_tr):\n",
        "            a_text = table_row.a.text\n",
        "            td_text = table_row.td.text\n",
        "            td_text = td_text.strip()\n",
        "            print(a_text,'(',td_text,')')\n",
        "            if i == n-1:\n",
        "                break\n",
        "except KeyError:\n",
        "    pass"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Recent News Headlines for SNP: \n",
            "Sinopec (SNP) Jumps More Than 13% on Q3 Earnings Improvement ( Nov-10-20 08:55AM )\n",
            "China Ready to Pick Up Slack With Global Oil Demand Wavering ( Nov-09-20 10:17PM )\n",
            "Sinopec's Net Profit for 2020 Q3 Reached RMB 23.507 Billion Campaign of Continuously Tiding Over Difficulties and Improving Performances Achieves Favorable Results with Significant Improvement of Operation and Profitability ( Oct-28-20 11:05PM )\n",
            "China's Sinopec flips to quarterly profit on robust refining business ( 06:44AM )\n",
            "China Recruits a South Korean Conglomerate to Advise on ESG ( Oct-18-20 10:25PM )\n",
            "\n",
            "\n",
            "Recent News Headlines for PTR: \n",
            "China Ready to Pick Up Slack With Global Oil Demand Wavering ( Nov-09-20 10:17PM )\n",
            "PetroChina (PTR) Q3 Earnings Jump on Pipeline Spin-Off Gains ( 08:32AM )\n",
            "PetroChina Company Limited (PTR) Q3 2020 Earnings Call Transcript ( Oct-30-20 11:01PM )\n",
            "Zero Hour Is Coming for Emissions. Believe It ( Oct-25-20 06:00PM )\n",
            "PetroChina Company (PTR) Enters Oversold Territory ( Oct-21-20 06:36AM )\n",
            "\n",
            "\n",
            "Recent News Headlines for BP: \n",
            "Nikola CEO: We are prepared to 'go to market alone if we have to,' without General Motors ( Nov-10-20 12:18PM )\n",
            "BP Launches Green Hydrogen Project With Danish Energy Giant Ã˜rsted. The Stock Is Surging. ( 08:20AM )\n",
            "Shell upped to buy at HSBC, which also keeps BP and Total at buy ( Nov-09-20 09:42AM )\n",
            "Ghost Rigs Could Become The New Normal In Offshore Oil ( Nov-08-20 03:00PM )\n",
            "Bidens Energy Plan Is Only as Ambitious as BPs ( 11:14AM )\n",
            "\n",
            "\n",
            "Recent News Headlines for XOM: \n",
            "Is Exxon Stock A Buy While Dividend Holds Steady Amid Steep Cuts? ( Nov-10-20 12:30PM )\n",
            "The 3 Riskiest Robinhood Stocks to Hold Right Now ( 06:10AM )\n",
            "The 2 Most Surprising Stock Market Winners Today ( Nov-09-20 04:24PM )\n",
            "Exxon Mobil Leads Energy Shares Higher On Pfizer Vaccine Boost: U.S. Crude Surges Past $40 A Barrel ( 01:57PM )\n",
            "Shell upped to buy at HSBC, which also keeps BP and Total at buy ( 09:42AM )\n",
            "\n",
            "\n",
            "Recent News Headlines for TOT: \n",
            "Total and its Partners Release Next-Generation & Open-Source Geological Carbon Dioxide Storage Simulator ( Nov-10-20 04:20AM )\n",
            "My Top Oil Stock to Buy Right Now ( Nov-05-20 10:45AM )\n",
            "BP vs. Total: Which Oil Company Is Better Positioned for a Green Energy Transition? ( Oct-31-20 10:35AM )\n",
            "3 Top Energy Stocks to Buy Ahead of the Election ( 07:36AM )\n",
            "TOTAL SA (TOT) Q3 2020 Earnings Call Transcript ( Oct-30-20 08:30PM )\n",
            "\n",
            "\n",
            "Recent News Headlines for CVX: \n",
            "Is Chevron Stock A Buy Now As Permian Basin Footprint Grows? ( Nov-10-20 10:25AM )\n",
            "2 Energy Stocks With Promise: A Technical Look ( 09:46AM )\n",
            "Big Oil Stocks Are Soaring on COVID-19 Vaccine News Today ( Nov-09-20 10:57AM )\n",
            "Shell upped to buy at HSBC, which also keeps BP and Total at buy ( 09:42AM )\n",
            "Forget Exxon, These 3 Energy Stocks Are Better Buys Right Now ( Nov-07-20 08:24AM )\n",
            "\n",
            "\n",
            "Recent News Headlines for MPC: \n",
            "No Stimulus? This Expansion Still Looks Self-Sustaining, Says One Economist ( Nov-06-20 08:15PM )\n",
            "Analyzing Marathon Petroleum's Unusual Options Activity ( Nov-04-20 09:34AM )\n",
            "Marathon Petroleum (MPC) Q3 2020 Earnings Call Transcript ( Nov-02-20 07:31PM )\n",
            "Marathon Petroleum Rises After Narrower-Than-Expected Loss ( 12:20PM )\n",
            "Marathon (MPC) Q3 Loss Narrower Than Expected, Sales Miss ( 09:28AM )\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzDUkD1JTtCN"
      },
      "source": [
        "#a_text = re.sub(r'Chapter \\d+', '', a_text)\n",
        "#print('Chapter headings removed:', url[0:100])"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lot9F3kDShdl"
      },
      "source": [
        "#url = ' '.join(url.split())\n",
        "\n",
        "#print('extra whitespace removed:', a_text[0:100])"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M50jzaDsUU1B"
      },
      "source": [
        "# Remove newlines and other extra whitespace by splitting and rejoining\n",
        "#url = ' '.join(a_text.split())\n",
        "#print('Extra whitespace removed:', url)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPKP5CluVic-"
      },
      "source": [
        "#Tokenization\n",
        "#nlp = spacy.load('en')\n",
        "#url_doc=nlp(url)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGrZS-NUV5zu",
        "outputId": "ccaee385-56d8-4441-ddc8-b24333f561d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Explore the objects that you've built.\n",
        "print(\"The url_doc object is a {} object.\".format(type(url_doc)))\n",
        "print(\"It is {} tokens long\".format(len(url_doc)))\n",
        "print(\"The first three tokens are '{}'\".format(url_doc[:3]))\n",
        "print(\"The type of each token is {}\".format(type(url_doc[0])))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The url_doc object is a <class 'spacy.tokens.doc.Doc'> object.\n",
            "It is 12 tokens long\n",
            "The first three tokens are 'Marathon (MPC'\n",
            "The type of each token is <class 'spacy.tokens.token.Token'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vGjtDVcWXg5"
      },
      "source": [
        "#removing stop words:\n",
        "url_without_stopwords = [token for token in url_doc if not token.is_stop]\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42POjixrW2sx",
        "outputId": "18b6ad55-b82a-47f5-8a37-f5b13444dd6c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Utility function to calculate how frequently words appear in the text\n",
        "def word_frequencies(text):\n",
        "    \n",
        "    # Build a list of words\n",
        "    # Strip out punctuation\n",
        "    words = []\n",
        "    for token in text:\n",
        "        if not token.is_punct:\n",
        "            words.append(token.text)\n",
        "            \n",
        "    # Build and return a `Counter` object containing word counts\n",
        "    return Counter(words)\n",
        "\n",
        "# Instantiate your list of the most common words\n",
        "url_word_freq = word_frequencies(url_without_stopwords).most_common(10)\n",
        "print('\\nurl:', url_word_freq)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "url: [('Marathon', 1), ('MPC', 1), ('Q3', 1), ('Loss', 1), ('Narrower', 1), ('Expected', 1), ('Sales', 1), ('Miss', 1)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUEwZIfQlGJE"
      },
      "source": [
        " #Iterate through the news\n",
        "parsed_news = []\n",
        "for file_name, news_table in news_tables.items():\n",
        "    for x in news_table.findAll('tr'):\n",
        "        text = x.a.get_text() \n",
        "        date_scrape = x.td.text.split()\n",
        "\n",
        "        if len(date_scrape) == 1:\n",
        "            time = date_scrape[0]\n",
        "            \n",
        "        else:\n",
        "            date = date_scrape[0]\n",
        "            time = date_scrape[1]\n",
        "\n",
        "        ticker = file_name.split('_')[0]\n",
        "        \n",
        "        parsed_news.append([ticker, date, time, text])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vS57KACols3b",
        "outputId": "818222e5-0757-47fb-a59b-b4978a18ead8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('vader_lexicon')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDz4OdKNMhuI",
        "outputId": "8d3f071f-1daa-4f21-b9a9-7e228ac88b39",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2eJ9WmBK8mE"
      },
      "source": [
        "from nltk import sent_tokenize\n",
        "sents = sent_tokenize(url)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izcYMgj7lGL8"
      },
      "source": [
        "# Sentiment Analysis\n",
        "analyzer = SentimentIntensityAnalyzer()\n",
        "\n",
        "columns = ['Ticker', 'Date', 'Time', 'Headline']\n",
        "news = pd.DataFrame(parsed_news, columns=columns)\n",
        "scores = news['Headline'].apply(analyzer.polarity_scores).tolist()\n",
        "\n",
        "df_scores = pd.DataFrame(scores)\n",
        "news = news.join(df_scores, rsuffix='_right')"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhpK8m5tlGOk"
      },
      "source": [
        "# View Data \n",
        "news['Date'] = pd.to_datetime(news.Date).dt.date"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBk8keR0lGRd"
      },
      "source": [
        "unique_ticker = news['Ticker'].unique().tolist()\n",
        "news_dict = {name: news.loc[news['Ticker'] == name] for name in unique_ticker}"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKTTsWNjlGUV",
        "outputId": "26efb3dd-bee6-4c6e-fdc2-02c5c8289a5d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "values = []\n",
        "for ticker in tickers: \n",
        "    dataframe = news_dict[ticker]\n",
        "    dataframe = dataframe.set_index('Ticker')\n",
        "    dataframe = dataframe.drop(columns = ['Headline'])\n",
        "    print ('\\n')\n",
        "    print (dataframe.head())\n",
        "    \n",
        "    mean = round(dataframe['compound'].mean(), 2)\n",
        "    values.append(mean)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "              Date     Time    neg    neu    pos  compound\n",
            "Ticker                                                    \n",
            "SNP     2020-11-10  08:55AM  0.000  0.750  0.250    0.4588\n",
            "SNP     2020-11-09  10:17PM  0.228  0.588  0.184    0.1027\n",
            "SNP     2020-10-28  11:05PM  0.055  0.521  0.424    0.9169\n",
            "SNP     2020-10-28  06:44AM  0.000  0.602  0.398    0.6486\n",
            "SNP     2020-10-18  10:25PM  0.000  1.000  0.000    0.0000\n",
            "\n",
            "\n",
            "              Date     Time    neg    neu    pos  compound\n",
            "Ticker                                                    \n",
            "PTR     2020-11-09  10:17PM  0.228  0.588  0.184    0.1027\n",
            "PTR     2020-11-09  08:32AM  0.000  0.769  0.231    0.3400\n",
            "PTR     2020-10-30  11:01PM  0.192  0.808  0.000   -0.2263\n",
            "PTR     2020-10-25  06:00PM  0.000  1.000  0.000    0.0000\n",
            "PTR     2020-10-21  06:36AM  0.000  1.000  0.000    0.0000\n",
            "\n",
            "\n",
            "              Date     Time    neg    neu    pos  compound\n",
            "Ticker                                                    \n",
            "BP      2020-11-10  12:18PM  0.106  0.794  0.101   -0.0258\n",
            "BP      2020-11-10  08:20AM  0.000  0.861  0.139    0.2732\n",
            "BP      2020-11-09  09:42AM  0.000  1.000  0.000    0.0000\n",
            "BP      2020-11-08  03:00PM  0.204  0.796  0.000   -0.3182\n",
            "BP      2020-11-08  11:14AM  0.000  0.574  0.426    0.6369\n",
            "\n",
            "\n",
            "              Date     Time    neg    neu    pos  compound\n",
            "Ticker                                                    \n",
            "XOM     2020-11-10  12:30PM  0.180  0.820  0.000   -0.2960\n",
            "XOM     2020-11-10  06:10AM  0.263  0.737  0.000   -0.3612\n",
            "XOM     2020-11-09  04:24PM  0.000  0.477  0.523    0.6697\n",
            "XOM     2020-11-09  01:57PM  0.163  0.529  0.308    0.3182\n",
            "XOM     2020-11-09  09:42AM  0.000  1.000  0.000    0.0000\n",
            "\n",
            "\n",
            "              Date     Time  neg    neu    pos  compound\n",
            "Ticker                                                  \n",
            "TOT     2020-11-10  04:20AM  0.0  1.000  0.000    0.0000\n",
            "TOT     2020-11-05  10:45AM  0.0  0.795  0.205    0.2023\n",
            "TOT     2020-10-31  10:35AM  0.0  0.688  0.312    0.6124\n",
            "TOT     2020-10-31  07:36AM  0.0  0.642  0.358    0.4404\n",
            "TOT     2020-10-30  08:30PM  0.0  1.000  0.000    0.0000\n",
            "\n",
            "\n",
            "              Date     Time    neg    neu    pos  compound\n",
            "Ticker                                                    \n",
            "CVX     2020-11-10  10:25AM  0.000  1.000  0.000    0.0000\n",
            "CVX     2020-11-10  09:46AM  0.000  0.476  0.524    0.5267\n",
            "CVX     2020-11-09  10:57AM  0.000  1.000  0.000    0.0000\n",
            "CVX     2020-11-09  09:42AM  0.000  1.000  0.000    0.0000\n",
            "CVX     2020-11-07  08:24AM  0.137  0.504  0.360    0.4767\n",
            "\n",
            "\n",
            "              Date     Time    neg    neu  pos  compound\n",
            "Ticker                                                  \n",
            "MPC     2020-11-06  08:15PM  0.196  0.804  0.0   -0.2960\n",
            "MPC     2020-11-04  09:34AM  0.000  1.000  0.0    0.0000\n",
            "MPC     2020-11-02  07:31PM  0.000  1.000  0.0    0.0000\n",
            "MPC     2020-11-02  12:20PM  0.315  0.685  0.0   -0.3182\n",
            "MPC     2020-11-02  09:28AM  0.358  0.642  0.0   -0.4404\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7O-TFqvhlGW9",
        "outputId": "8f88a743-76eb-4848-e90b-78c97a3cfb52",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df = pd.DataFrame(list(zip(tickers, values)), columns =['Ticker', 'Mean Sentiment']) \n",
        "df = df.set_index('Ticker')\n",
        "df = df.sort_values('Mean Sentiment', ascending=False)\n",
        "print ('\\n')\n",
        "print (df)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "        Mean Sentiment\n",
            "Ticker                \n",
            "TOT               0.13\n",
            "CVX               0.03\n",
            "SNP               0.02\n",
            "BP                0.01\n",
            "MPC               0.00\n",
            "PTR              -0.02\n",
            "XOM              -0.07\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldYuBgHilGZ2"
      },
      "source": [
        ""
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4nLKRL0lGc0"
      },
      "source": [
        ""
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7ferOQklGfv"
      },
      "source": [
        ""
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcirW3BdlGim"
      },
      "source": [
        ""
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UO52BLdelGlp"
      },
      "source": [
        ""
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1ItSp-llGpS"
      },
      "source": [
        ""
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZs6MDHvlGse"
      },
      "source": [
        ""
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2u8j4SszlGvg"
      },
      "source": [
        ""
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFqvyJvSlGzO"
      },
      "source": [
        ""
      ],
      "execution_count": 20,
      "outputs": []
    }
  ]
}